{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5934bc5f-9463-4818-856e-2544b3d963d2",
   "metadata": {},
   "source": [
    "# Generating image captions using the BLIP model\n",
    "### Import the required tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3712e017-4d0d-4d34-bb54-d1acd07a6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
    "# Disable tensorflow warnings (program uses Pytorch)\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "import tensorflow as tf\n",
    "# Disable hugging face warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54804799-6bf6-4546-afe9-851f74742ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e649b123-a55a-4d3f-8b1e-2d4555455803",
   "metadata": {},
   "source": [
    "### Fetch the model and intialize a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0444c097-2668-4bb2-b3b4-bc05c0983eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test image\n",
    "img_path = \"valentin-jorel-Mpyn-ne644Y-unsplash.jpg\"\n",
    "# Convert the image into an RGB format\n",
    "image = Image.open(img_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e10d7d-f11b-4d33-8e43-736232596c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the processed image to the processor and generate the inputs\n",
    "text = \"The image of\"\n",
    "inputs = processor(images=image, text=text, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5159820b-a1e8-4715-816f-ee431db5467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass inputs into model generate method to create caption (set to 50 tokens max)\n",
    "outputs = model.generate(**inputs, max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fdb2bf-ccba-4922-9335-86df49d92490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the image of a gorilla\n"
     ]
    }
   ],
   "source": [
    "# Decode the generated tokens to human-readable text\n",
    "caption = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "# Print the caption\n",
    "print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359afe8-ae7b-4066-b2e3-e523589effc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
